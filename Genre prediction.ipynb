{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(open(\".\\\\data\\\\train_features.tsv\", encoding=\"utf8\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\".\\\\data\\\\train_labels.tsv\", encoding='utf8'), sep = '\\t')\n",
    "valid_data = pd.read_csv(open(\".\\\\data\\\\valid_features.tsv\", encoding=\"utf8\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\".\\\\data\\\\valid_labels.tsv\", encoding=\"utf8\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(open('test_features.csv', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(test_data, model):\n",
    "    #Unpacks the model and count vectoriser, and transforms the test instances into a format usable by the model\n",
    "    modelLR, vectoriser = model\n",
    "    tag_data = pd.DataFrame(vectoriser.transform(test_data['tag']).toarray())\n",
    "    av_data = test_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Predictions are made, and the result saved to file\n",
    "    y_pred = modelLR.predict(data_transformed)\n",
    "    df = pd.DataFrame()\n",
    "    df['movieId'] = test_data['movieId']\n",
    "    df['genres'] = y_pred\n",
    "    df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(train_data, train_labels):\n",
    "    #Convert tags to a vector of word frequencies\n",
    "    vectoriser = CountVectorizer()\n",
    "    X = vectoriser.fit_transform(train_data['tag'])\n",
    "    \n",
    "    #Train Multinomial NB model.\n",
    "    nbModel = MultinomialNB()\n",
    "    nbModel.fit(X, train_labels['genres'])\n",
    "    return (nbModel, vectoriser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNB(model, valid_data, valid_labels):\n",
    "    \n",
    "    #Unpack model and vectoriser, and transform data to useable format\n",
    "    nbModel, vectoriser = model\n",
    "    X = vectoriser.transform(valid_data['tag'])\n",
    "    \n",
    "    #Predictions made, evaluation metrics calculated.\n",
    "    y_pred = nbModel.predict(X)\n",
    "    y_true = valid_labels['genres']\n",
    "    f1_score_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    acc = nbModel.score(X, y_true)\n",
    "    labels = nbModel.classes_\n",
    "    \n",
    "    #Evaluation results printed\n",
    "    print(labels)\n",
    "    print(confusion_matrix(y_true,y_pred,labels=labels))    \n",
    "    print('Weighted f-score: ', f1_score_weighted)\n",
    "    print('Total accuracy: ', acc) \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage of Naive Bayes baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adventure' 'Animation' 'Children' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film_Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci_Fi' 'Thriller' 'War' 'Western']\n",
      "[[ 0  0  0  0  1  0  0  3  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1 19  0  0  4  0  0  0  0  0 13  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  1  0  8  7  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  3 24  0  0  0  0  0  6  2  3  0  0]\n",
      " [ 1  0  0  1  2  0  0  2  6  0  3  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  0  0  3  0  0  1  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  3  1  1  0  0  1  0  4  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  6  0  0  1  0  2  0  2  5  0  0]\n",
      " [ 0  0  0  0  8  0  0 13  0  0  1  0  0 24  2  3  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  1  0  0  0  0  1 12  0  0  0]\n",
      " [ 0  0  0  1  1  3  0  5  1  1  1  0  0  4  1 10  0  0]\n",
      " [ 0  0  0  0  1  0  0  4  1  0  0  0  0  6  2  0  7  0]\n",
      " [ 0  0  0  0  1  0  0  2  0  0  0  2  0  2  0  0  0  0]]\n",
      "Weighted f-score:  0.3748971831668218\n",
      "Total accuracy:  0.39464882943143814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "modelNB = trainNB(train_data, train_labels)\n",
    "evaluateNB(modelNB, valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLR(train_data, train_labels):\n",
    "    #Convert tags to a vector of word frequencies, concatenate with audio-visual data\n",
    "    vectoriser = CountVectorizer()\n",
    "    tag_data = pd.DataFrame(vectoriser.fit_transform(train_data['tag']).toarray())\n",
    "    av_data = train_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Train logistic regression model, with lasso regularisation. \n",
    "    modelLR = LogisticRegression(random_state=0, penalty='l1').fit(data_transformed, train_labels['genres'])\n",
    "    return (modelLR, vectoriser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLR(model, valid_data, valid_labels):\n",
    "    #Unpack model and vectoriser, transform data into useable format\n",
    "    modelLR, vectoriser = model\n",
    "    tag_data = pd.DataFrame(vectoriser.transform(valid_data['tag']).toarray())\n",
    "    av_data = valid_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Make predictions and calculate evaluation metrics\n",
    "    y_pred = modelLR.predict(data_transformed)\n",
    "    y_true = valid_labels['genres']\n",
    "    acc = modelLR.score(data_transformed, y_true)\n",
    "    labels = list(set(valid_labels['genres']))\n",
    "    precision = pd.DataFrame(precision_score(y_true, y_pred, labels=labels, average=None))\n",
    "    recall = pd.DataFrame(recall_score(y_true, y_pred, labels=labels, average=None))\n",
    "    prec_recall = pd.concat([precision, recall], axis=1)\n",
    "    prec_recall.columns = ['precision', 'recall']\n",
    "    prec_recall.index = labels\n",
    "    f1_score_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    #Print evaluation results.\n",
    "    print(labels)\n",
    "    print(confusion_matrix(y_true,y_pred,labels=labels))\n",
    "    print(prec_recall)\n",
    "    print('Weighted f-score: ', f1_score_weighted)\n",
    "    print('Total accuracy: ', acc) \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model with weightings to balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLRBalanced(train_data, train_labels):\n",
    "    #Convert tags to a vector of word frequencies and concatenate with AV data.\n",
    "    vectoriser = CountVectorizer()\n",
    "    tag_data = pd.DataFrame(vectoriser.fit_transform(train_data['tag']).toarray())\n",
    "    av_data = train_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Train model using balanced weightings.\n",
    "    modelLR = LogisticRegression(random_state=0, class_weight='balanced', penalty='l1').fit(data_transformed, train_labels['genres'])\n",
    "    return (modelLR, vectoriser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation that takes top two label predictions, and outputs true if correct label is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMultiLR(model, valid_data, valid_labels):\n",
    "    #Unpacks model and vectoriser, concatenates with AV data.\n",
    "    modelLR, vectoriser = model\n",
    "    tag_data = pd.DataFrame(vectoriser.transform(valid_data['tag']).toarray())\n",
    "    av_data = valid_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Makes two predictions for each instance\n",
    "    y_prob = modelLR.predict_proba(data_transformed)\n",
    "    y_pred = []\n",
    "    for row in y_prob:\n",
    "        row = list(enumerate(row))\n",
    "        row = sorted(row, reverse=True, key=lambda x:x[1])\n",
    "        y_pred.append((modelLR.classes_[row[0][0]], modelLR.classes_[row[1][0]]))\n",
    "    \n",
    "    #Calculates accuracy where it is correct if true label is one of the two predicted classes.\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        count += 1\n",
    "        if valid_labels['genres'][i] in y_pred[i]:\n",
    "            correct += 1\n",
    "    acc = correct / count\n",
    "    print(acc)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of logistic regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Training regular model LR1\n",
    "modelLR = trainLR(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comedy', 'Children', 'Animation', 'Romance', 'Musical', 'Action', 'Horror', 'Crime', 'Film_Noir', 'Fantasy', 'Thriller', 'Western', 'Drama', 'Sci_Fi', 'Mystery', 'War', 'Documentary', 'Adventure']\n",
      "[[22  0  0  7  1  0  0  0  0  2  1  0  4  0  1  0  0  0]\n",
      " [ 0  1  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0 18  0  0  1  0  0  0  5  1 17  2  0  0  0  0]\n",
      " [ 2  0  0  2  1  0  0  0  0  2  0  0  1  0  0  0  2  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  1  0]\n",
      " [ 0  0  0  1  0  0  5  0  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  2  0  1  0  0  0  0  0]\n",
      " [ 1  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  1  1  4  0  0  6  0  0  3  0  0  0  0  0]\n",
      " [ 1  0  0  1  0  0  1  1  0  1 15  0  6  0  0  1  1  0]\n",
      " [ 2  0  1  1  1  0  0  0  0  0  0  0  1  0  0  0  1  0]\n",
      " [ 6  0  0  4  0  0  0  0  0  0  5  0 27  0  0  0  1  0]\n",
      " [ 0  1  0  2  0  0  0  0  0  0  1  0  2 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0 10  0  3  0  3  1  0  0]\n",
      " [ 2  0  0  3  0  0  0  0  0  0  1  0  6  1  0  7  0  1]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0]]\n",
      "             precision    recall\n",
      "Comedy        0.478261  0.578947\n",
      "Children      0.500000  0.333333\n",
      "Animation     0.500000  0.333333\n",
      "Romance       0.391304  0.352941\n",
      "Musical       0.166667  0.100000\n",
      "Action        0.000000  0.000000\n",
      "Horror        0.384615  0.625000\n",
      "Crime         0.500000  0.200000\n",
      "Film_Noir     0.000000  0.000000\n",
      "Fantasy       0.500000  0.333333\n",
      "Thriller      0.365854  0.535714\n",
      "Western       0.000000  0.000000\n",
      "Drama         0.325301  0.627907\n",
      "Sci_Fi        0.769231  0.625000\n",
      "Mystery       0.750000  0.166667\n",
      "War           0.777778  0.333333\n",
      "Documentary   0.647059  0.611111\n",
      "Adventure     0.000000  0.000000\n",
      "Weighted f-score:  0.40997002022893153\n",
      "Total accuracy:  0.4280936454849498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of model LR1 on validation data\n",
    "evaluateLR(modelLR, valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Training model LR2 with weightings to balance dataset\n",
    "modelLRBalanced = trainLRBalanced(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comedy', 'Children', 'Animation', 'Romance', 'Musical', 'Action', 'Horror', 'Crime', 'Film_Noir', 'Fantasy', 'Thriller', 'Western', 'Drama', 'Sci_Fi', 'Mystery', 'War', 'Documentary', 'Adventure']\n",
      "[[16  1  1  3  1  3  1  1  1  2  0  2  3  0  1  0  1  1]\n",
      " [ 0  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  0 11  1  0  2  3  3  1  2  1 11  2  1  0  4  0]\n",
      " [ 1  1  0  2  2  0  0  0  0  1  0  0  0  0  0  0  2  1]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  1  0  0  1  2  0]\n",
      " [ 0  0  0  0  0  0  5  0  0  0  1  1  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  1  0  2  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  2  1  5  0  0  6  0  0  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  1  2  3  0  1  8  0  3  0  4  2  2  0]\n",
      " [ 2  0  1  0  1  0  0  1  0  0  0  1  0  0  0  0  1  0]\n",
      " [ 4  0  1  1  0  1  0  2  1  0  5  3 15  0  0  1  9  0]\n",
      " [ 0  3  0  0  0  0  0  1  1  0  0  1  2  8  0  0  0  0]\n",
      " [ 0  0  1  0  1  1  1  1  1  0  6  0  1  0  3  1  1  0]\n",
      " [ 2  0  0  1  2  0  1  0  2  0  0  0  2  0  0  9  0  2]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1  3  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0]]\n",
      "             precision    recall\n",
      "Comedy        0.432432  0.421053\n",
      "Children      0.142857  0.333333\n",
      "Animation     0.333333  0.666667\n",
      "Romance       0.523810  0.215686\n",
      "Musical       0.166667  0.200000\n",
      "Action        0.166667  0.333333\n",
      "Horror        0.263158  0.625000\n",
      "Crime         0.142857  0.400000\n",
      "Film_Noir     0.000000  0.000000\n",
      "Fantasy       0.500000  0.333333\n",
      "Thriller      0.347826  0.285714\n",
      "Western       0.100000  0.142857\n",
      "Drama         0.333333  0.348837\n",
      "Sci_Fi        0.800000  0.500000\n",
      "Mystery       0.333333  0.166667\n",
      "War           0.642857  0.428571\n",
      "Documentary   0.371429  0.722222\n",
      "Adventure     0.000000  0.000000\n",
      "Weighted f-score:  0.35398122496712514\n",
      "Total accuracy:  0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model LR2\n",
    "evaluateLR(modelLRBalanced, valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "#Evaluating original LR1 model but using multi-label evaluation (LR3)\n",
    "evaluateMultiLR(modelLR, valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDT(train_data, train_labels):\n",
    "    #Transforms tag data into count vector, and concatenates with AV data.\n",
    "    vectoriser = CountVectorizer()\n",
    "    tag_data = pd.DataFrame(vectoriser.fit_transform(train_data['tag']).toarray())\n",
    "    av_data = train_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Trains model with decision tree, no restrictions on size\n",
    "    modelDT = DecisionTreeClassifier(random_state=0, criterion='entropy')\n",
    "    modelDT.fit(data_transformed, train_labels['genres'])\n",
    "    \n",
    "    return (modelDT, vectoriser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDT(model, valid_data, valid_labels):\n",
    "    #Unpacks model and vectoriser, transforms data into useable format\n",
    "    modelDT, vectoriser = model\n",
    "    tag_data = pd.DataFrame(vectoriser.transform(valid_data['tag']).toarray())\n",
    "    av_data = valid_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Makes predictions and calculates evaluation metrics\n",
    "    y_pred = modelDT.predict(data_transformed)\n",
    "    y_true = valid_labels['genres']\n",
    "    acc = modelDT.score(data_transformed, y_true)\n",
    "    f1_score_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    labels = modelDT.classes_\n",
    "    \n",
    "    #Prints evaluation results\n",
    "    print(labels)\n",
    "    print(confusion_matrix(y_true,y_pred,labels=labels))\n",
    "    print('Weighted f-score: ', f1_score_weighted)\n",
    "    print('Total accuracy: ', acc) \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree with restricted depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainReducedDT(train_data, train_labels):\n",
    "    #Transforms tag data into count vector, and concatenates with AV data.\n",
    "    vectoriser = CountVectorizer()\n",
    "    tag_data = pd.DataFrame(vectoriser.fit_transform(train_data['tag']).toarray())\n",
    "    av_data = train_data.drop(columns=['movieId','title','YTId','year','tag'])\n",
    "    data_transformed = pd.concat([tag_data,av_data],axis=1)\n",
    "    \n",
    "    #Trains model with decision tree, depth restricted to 7.\n",
    "    modelDT = DecisionTreeClassifier(random_state=0, max_depth=7)\n",
    "    modelDT.fit(data_transformed, train_labels['genres'])\n",
    "    \n",
    "    return (modelDT, vectoriser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of decision tree functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of unrestricted decision tree\n",
    "modelDT = trainDT(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adventure' 'Animation' 'Children' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film_Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci_Fi' 'Thriller' 'War' 'Western']\n",
      "[[ 86   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 104   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 106   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 583   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 237   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 207   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 713   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 298   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  78   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 244   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 154   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 270   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 791   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 417   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 598   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 241   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83]]\n",
      "Weighted f-score:  1.0\n",
      "Total accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of unrestricted decision tree on training data\n",
    "evaluateDT(modelDT, train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adventure' 'Animation' 'Children' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film_Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci_Fi' 'Thriller' 'War' 'Western']\n",
      "[[ 0  0  0  0  1  0  0  0  0  0  0  0  0  2  1  1  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 3  1  1  0 11  0  2  6  1  0  1  0  2  7  1  2  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  1  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  1  0  1  2  1  4  5  0  0  0  1  1  0  0  1  1  0]\n",
      " [ 0  2  2  1  4  2  1  9  1  0  1  1  3  9  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  4  0  2  0  0  4  4  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  1  0  0  0  3  0  2  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  2  2  0  0  0  1  1  0  1  2  0  0  0]\n",
      " [ 1  0  0  1  0  0  1  4  1  0  0  1  1  1  3  4  0  0]\n",
      " [ 1  3  0  0 11  2  0  6  3  0  1  1  1  8  5  6  3  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  0  0  0  0  1 11  1  0  0]\n",
      " [ 0  0  0  0  2  0  0  4  1  0  2  0  4  3  1  6  4  1]\n",
      " [ 0  2  0  0  1  1  2  1  3  0  1  1  2  2  2  1  2  0]\n",
      " [ 0  0  0  1  2  1  0  0  2  0  0  0  0  0  1  0  0  0]]\n",
      "Weighted f-score:  0.19610408318908543\n",
      "Total accuracy:  0.2040133779264214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of unrestricted decision tree on validation data\n",
    "evaluateDT(modelDT, valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of decision tree with restricted depth\n",
    "modelDT_7 = trainReducedDT(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adventure' 'Animation' 'Children' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film_Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci_Fi' 'Thriller' 'War' 'Western']\n",
      "[[  0   0   0   0  42   0   0   0   0   0   0   0   0   1   0  43   0   0]\n",
      " [  0   2   0   0  55   0   0   0   1   0   0   0   0   4   0  41   1   0]\n",
      " [  0   0   0   0  16   0   0   0   1   0   0   0   0   0   0  13   0   0]\n",
      " [  0   0   0   0  72   0   0   0   3   0   0   0   0   1   0  30   0   0]\n",
      " [  0   0   0   0 411   0   1   0   1   0   0   0   0   4   0 164   2   0]\n",
      " [  0   0   0   0 117   0   0   1   1   0   0   0   0   1   0 116   1   0]\n",
      " [  0   0   0   0  85   0  53   0   0   0   0   0   0   0   0  66   3   0]\n",
      " [  0   0   0   0 312   0   0   6   1   0   0   0   0   7   0 380   7   0]\n",
      " [  0   0   0   0  88   0   0   1  75   0   0   0   0   5   4 124   1   0]\n",
      " [  0   0   0   0  45   0   0   0   0   1   0   0   0   1   0  30   1   0]\n",
      " [  0   0   0   0  66   0   0   0   0   0   2   0   0   2   2 172   0   0]\n",
      " [  0   0   0   0  93   0   1   0   0   0   0  12   0   1   1  45   1   0]\n",
      " [  0   0   0   0  75   0   1   0   3   0   0   0  11   4   4 172   0   0]\n",
      " [  0   0   0   0 351   0   0   0   6   0   0   0   0 166   3 262   3   0]\n",
      " [  0   0   0   0 113   0   0   0   0   0   0   0   0   2 163 137   2   0]\n",
      " [  0   0   0   0 155   0   1   0   2   0   0   0   0   4   1 431   4   0]\n",
      " [  0   0   0   0  69   0   2   0   0   0   0   0   0   2   3  68  97   0]\n",
      " [  0   0   0   0  55   0   0   0   0   0   0   0   0   0   3  24   1   0]]\n",
      "Weighted f-score:  0.23422777720629284\n",
      "Total accuracy:  0.2729007633587786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating restricted decision tree on training data\n",
    "evaluateDT(modelDT_7, train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action' 'Adventure' 'Animation' 'Children' 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film_Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci_Fi' 'Thriller' 'War' 'Western']\n",
      "[[ 0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  0  0  0  0  0  1  0 11  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  9  0  3  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0 22  1  0]\n",
      " [ 0  0  0  0  3  0  0  0  4  0  0  0  0  2  1  8  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  4  0  2  0  0  0  0  0  0  1  1  2  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0  0  0  0  0  2 11  0  0]\n",
      " [ 0  0  0  0 20  0  0  1  0  0  0  0  1  6  0 23  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  2  9  2  0  0]\n",
      " [ 0  0  0  0  6  0  0  0  0  0  0  0  0  0  0 20  2  0]\n",
      " [ 0  0  0  0  8  0  0  0  0  0  0  0  0  0  1  8  4  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  3  0  0]]\n",
      "Weighted f-score:  0.18651070038492668\n",
      "Total accuracy:  0.2408026755852843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating restricted decision tree on validation data\n",
    "evaluateDT(modelDT_7, valid_data, valid_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
